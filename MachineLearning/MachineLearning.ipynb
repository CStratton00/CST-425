{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Machine Learning\n",
    "\n",
    "Andrew Esch, Evan Lee, Collin Stratton\n",
    "\n",
    "Dr. Isac Artzi\n",
    "\n",
    "CST-425\n",
    "\n",
    "4/17/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "The purpose of this assignment is to synthesize the complex aspects of machine learning. Specifically, this project will create an image model that will be able to predict the type of food an image of a food item is, and then pass in an image of a dog to see what type of food the dog is. This is a fun way to implement machine learning in a unique way to showcase the skills learned in this course."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project Description\n",
    "## Machine Learning Problem\n",
    "Image recognition is extremely useful and can be used in many ways. We have the idea of figuring out which foods a dog would be. This may not be a breakthrough project by itself but at its core can be very useful. Creating the model proved to take a very long time, but with the implementation of CUDA cores to speed up the image model using tensorflow and cv2, we looked to improve the code we found that creates the model. Machine learning models should utilize technology to the fullest and companies that are not implementing CUDA in their code could be losing lots of money and time on their models.\n",
    "\n",
    "## Problem Sketch\n",
    "See the images in the folder.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Code\n",
    "The outline of the code is as follows: First, the appropriate libraries are install and the images are loaded. Next, the images are labeled and categorized for preprocessing. Then, the images are preprocessed and the model is trained. Finally, the model is used to predict what type of food an image of a dog is.  \n",
    "\n",
    "## Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import cv2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Images and Label Data\n",
    "# About the dataset:\n",
    "Our dataset is from kaggle (link at the bottom) with 101 different foods and about 300 pictures per food item. Using this super in depth color image dataset, we are able to build an accurate model for these foods that will allow the best fit for any dog we enter into the model. Our data does not need to be normalized or standardized before it is used in the modeling process. There is no need to handle outliers for the pictures because all the foods in each folder are indeed the correct food, but possibly at an angle or presented differently but this would help our model instead of hurting it.\n",
    "\n",
    "# Explanation of Code:\n",
    "The first step is downloading the full dataset from kaggle and running it locally on our device. We decided to preform it locally instead of on GitHub since the file sizes would be too big. Then the os paths of the labels and food items are taken and put in a pandas dataframe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import images\n",
    "# andrew_dir = Path('C:/Users/Drew/OneDrive/Pictures/ml-food/images')\n",
    "evan_dir = Path('C:/GCU Academics/Junior Year/Second Semester/CST-425/Food Dataset/FoodFiles/images')\n",
    "# collin_dir = Path('/Users/collinstratton/Documents/archive/images')\n",
    "\n",
    "image_dir = Path(evan_dir)\n",
    "images_paths = list(image_dir.glob(r'**/*.jpg'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], images_paths))\n",
    "\n",
    "images_paths = pd.Series(images_paths, name='Image_Path').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "images = pd.concat([images_paths, labels], axis=1)\n",
    "print(\"First chunk done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split images into categories\n",
    "category_samples = []\n",
    "for category in images['Label'].unique():\n",
    "    category_slice = images.query('Label == @category')\n",
    "    category_samples.append(category_slice.sample(300, random_state=1))\n",
    "\n",
    "# group images into tables and check the number of images by category\n",
    "images_samples = pd.concat(category_samples, axis=0)\n",
    "images_samples['Label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess Images\n",
    "# Building the model:\n",
    "We use sklearn to create a training and testing image dataset with a 70/30 split. We then will use keras to preform preprocessing on the images on both the training and testing set. We decided to use 10 epochs or 10 passthroughs of the model which nets around a 90% accuracy for food items. On CPU alone it will take over an hour to run but CUDA will significantly decrease that time."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing and training\n",
    "train_data, test_data = train_test_split(images_samples, train_size=0.7, shuffle=True, random_state=1)\n",
    "\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_data,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg',\n",
    ")\n",
    "\n",
    "# freeze the weights of the network to maintain transfer learning\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "inputs = pretrained_model.input\n",
    "\n",
    "# create two layers of our own\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# create output layer with the 101 classes\n",
    "output_layer = tf.keras.layers.Dense(101, activation='softmax')(x)\n",
    "\n",
    "# unite the original model with the new layers\n",
    "model = tf.keras.Model(inputs, output_layer)\n",
    "\n",
    "print(model.summary())\n",
    "print(\"chunk done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "328/531 [=================>............] - ETA: 1:49 - loss: 3.2947 - accuracy: 0.2317"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Training Results - Prediction Accuracy\n",
    "results = model.evaluate(test_images, verbose=1)\n",
    "print(\"Precision: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# find what food a dog image looks like\n",
    "# 'C:/GCU Academics/Junior Year/Second Semester/CST-425/CLC Shared GitHub Repository/Cloned Repository/MachineLearning/Daisy Pic.png'\n",
    "#'/Users/collinstratton/Documents/archive/dog_images/17DOGS-mobileMasterAt3x-v2.jpg'\n",
    "img = Image.open('/Users/collinstratton/Documents/archive/dog_images/17DOGS-mobileMasterAt3x-v2.jpg')\n",
    "img.show()\n",
    "\n",
    "img = np.array(img).astype(float) / 255\n",
    "\n",
    "img = cv2.resize(img, (224, 224))\n",
    "predict = model.predict(img.reshape(-1, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the result\n",
    "key_list = list(test_images.class_indices.keys())\n",
    "value_list = list(test_images.class_indices.values())\n",
    "\n",
    "position = value_list.index(np.argmax(predict))\n",
    "print(key_list[position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Conclusion\n",
    "This project was a fun way to implement machine learning in a unique way to showcase the skills learned in this course. The code is very simple and the results are very interesting. Even those the model was trained to be able to predict what type of food is in an image, it is versatile enough to be able to predict what type of food a dog is. The model got up to 80% accuracy on the food set, so we can only assume its high accuracy in predicting what type of food a dog is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Resources\n",
    "https://www.kaggle.com/datasets/kmader/food41\n",
    "\n",
    "https://www.kaggle.com/code/sergiogarridomerino/clasificaci-n-de-comida\n",
    "\n",
    "https://images.cv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}