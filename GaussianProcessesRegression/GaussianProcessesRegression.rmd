---
title: "Gaussian Processes Regression"
author: "Andrew Esch, Evan Lee, and Collin Stratton"
date: "3-13-2022"
output: html_notebook
---

## Introduction: Gene Expression and Differential Expressions
Gene Expression is the biological process found in cells in which genetic information (coded in the set of bases A, G, T, and C) is decoded and utilized to form a set of genetic products. It is a tightly regulated process which allows cells to respond to its changing environments, and it acts as an on/off switch or a protein volume controller to increase or decrease the amount of proteins being product. There are two major steps involved in gene expression, those being transcription and translation. Transcription is the copying of a DNA gene to produce a RNA transcript called mRNA. Translation takes the information from the mRNA, reads the amino acids on the strand using tRNA, then builds a polypeptide chain from the correct codes. The types of products that the process of gene expression can produce includes amino acids and proteins. This process is essential foundation for the formation of all biological life, and the differences in gene expression between cells is an important area of biology for further study.

Differential expression is the observation of a statistically significant difference or change in read counts or expression levels. To find a differential expression between genes, it is important to use statistical models to find if there is statistically significant difference for these metrics.

## Control and Treatment Categorizations
A control is a group categorization that does not have any affected conditions. In other words, this group acts as the baseline for all other measurements in a model. The standard for most models is to feature one control. Alternatively, a treatment is a type of group categorization that has been affected by some type of condition. They are also known as experimental group categorizations. A model may feature several treatments.

## Setup
```{r}
#RUN ONCE THEN COMMENT OUT
# if (!requireNamespace("BiocManager"))
   # install.packages("BiocManager")
# BiocManager::install(c("limma", "edgeR", "Glimma", "org.Mm.eg.db", "gplots", "RColorBrewer", "NMF", "BiasedUrn"))

library(edgeR)
library(limma)
library(Glimma)
library(org.Mm.eg.db)
library(gplots)
library(RColorBrewer)
library(NMF)
library(MASS)
library(plyr)
library(reshape2)
library(ggplot2)
library(GauPro)
library(kernlab)
set.seed(1234)
```

```{r Import Data}
#Evan Import -> C:/GCU Academics/Junior Year/Second Semester/CST-425/CLC Shared GitHub Repository/Cloned Repository/GaussianProcessesRegression/

#Andrew Import -> C:/Users/andre/Documents/GitHub/CST-425/GaussianProcessesRegression/

#Collin Import -> /Users/collinstratton/Google Drive/School/GCU/Fall 2021 - Spring 2022/CST-425/CST-425/GaussianProcessesRegression/

# Read the data into R
seqdata <- read.delim("C:/Users/andre/Documents/GitHub/CST-425/GaussianProcessesRegression/GSE60450_LactationGenewiseCounts.txt", stringsAsFactors = FALSE)
# Read the sample information into R
sampleinfo <- read.delim("C:/Users/andre/Documents/GitHub/CST-425/GaussianProcessesRegression/SampleInfo.txt", stringsAsFactors = TRUE)

head(seqdata)
dim(seqdata)

sampleinfo
```

```{r Format Data}
# Remove first two columns from seqdata
countdata <- seqdata[,-(1:2)]

# Look at the output
head(countdata)

colnames(countdata)
# using substr, you extract the characters starting at position 1 and stopping at position 7 of the colnames
colnames(countdata) <- substr(colnames(countdata),start=1,stop=7)
head(countdata)
```

### Create a DGEList Object
The DGEList is an object used by edgeR to store count data. It has a number of slots for storing various parameters about the data.
```{r DGEList}
dglist <- DGEList(countdata)

dglist
names(dglist)

group <- paste(sampleinfo$CellType,sampleinfo$Status,sep=".")
group <- factor(group)
group

dglist$samples$group <- group
dglist$samples
```

```{r Annotations}
columns(org.Mm.eg.db)
```

## Filtering Out Genes
Listed genes with very low counts provide little evidence for differential expression, and they interfere with some statistical approximations. Furthermore, they also add to the multiple testing burden when estimating false discovery rates, reducing power to detect differentially expressed genes. Thus, this next block of code filters out genes with very low counts.
```{r Filtering Out Genes}
# Obtain CPMs
myCPM <- cpm(countdata)

# Have a look at the output
head(myCPM)

# Which values in myCPM are greater than 0.5?
thresh <- myCPM > 0.5

# This produces a logical matrix with TRUEs and FALSEs
head(thresh)

# Summary of how many TRUEs there are in each row
# There are 11433 genes that have TRUEs in all 12 samples.
table(rowSums(thresh))

# we would like to keep genes that have at least 2 TRUES in each row of thresh
keep <- rowSums(thresh) >= 2
summary(keep)

# Let's have a look and see whether our threshold of 0.5 does indeed correspond to a count of about 10-15
# We will look at the first sample
plot(myCPM[,1],countdata[,1])

# Let us limit the x and y-axis so we can actually look to see what is happening at the smaller counts
plot(myCPM[,1],countdata[,1],ylim=c(0,50),xlim=c(0,3))
# Add a vertical line at 0.5 CPM
abline(v=0.5)

dglist <- dglist[keep, keep.lib.sizes=FALSE]
```

## Quality Control
With all the low-count genes filtering out, quality control of the data can now proceed. These next sections will look at graphs to be able to determine whether the data is appropriate for further analysis.
```{r Quality Control}
dglist$samples$lib.size

# The names argument tells the barplot to use the sample names on the x-axis
# The las argument rotates the axis names

barplot(dglist$samples$lib.size/1e06, names=colnames(dglist), las=2, ann=FALSE, cex.names=0.75)
mtext(side = 1, text = "Samples", line = 4)
mtext(side = 2, text = "Library size (millions)", line = 3)
title("Barplot of library sizes")

# Get log2 counts per million
logcounts <- cpm(dglist,log=TRUE)
# Check distributions of samples using boxplots
boxplot(logcounts, xlab="", ylab="Log2 counts per million",las=2)
# Let's add a blue horizontal line that corresponds to the median logCPM
abline(h=median(logcounts),col="blue")
title("Boxplots of logCPMs (unnormalised)")
```

```{r Normalize DGELIST}
logcounts <- cpm(dglist,log=TRUE)
# Apply normalisation to DGEList object
dglist <- calcNormFactors(dglist)
dglist$samples

```

```{r Graphing DGELSIT}
par(mfrow=c(1,2))

for(x in 1:12){
  plotMD(logcounts,column = x)
  abline(h=0,col="grey")
  plotMD(dglist,column = x)
  abline(h=0,col="grey")
}

```

```{r Differential Expression}
# Specify a design matrix without an intercept term
design <- model.matrix(~ 0 + group)
colnames(design) <- levels(group)
design
```

```{r VoomTransform}
# Generate a Voom (Mean-variance trend) graph and EList using the normalized factors
par(mfrow=c(1,1))
vtransform <- voom(dglist,design,plot = TRUE) # Create a plot representing this data
vtransform # Summarize the generated EList object
names(vtransform)
```

```{r showVoomTransformComparison}
par(mfrow=c(1,2))
boxplot(logcounts, xlab="", ylab="Log2 counts per million",las=2,main="Unnormalised logCPM")
## Let's add a blue horizontal line that corresponds to the median logCPM
abline(h=median(logcounts),col="blue")
boxplot(vtransform$E, xlab="", ylab="Log2 counts per million",las=2,main="Voom transformed logCPM")
## Let's add a blue horizontal line that corresponds to the median logCPM
abline(h=median(vtransform$E),col="blue")
```

```{r testDifferentialExpression}
# Using the normalized voom transform, we can test for differential expressions using limma

# Step 1: Create a linear model to represent each gene in the data using lmFit
fitted <- lmFit(vtransform) # Estimate the means and variances of each group using a design matrix
names(fitted) # Check the names of the items. Many of these are related to statisitcal testing, but it is important to ensure that the

# Step 2: Check for differential expression between the pregnant and lactating groups in basal cells.
contrastsMatrix <- makeContrasts(B.PregVsLac=basal.pregnant - basal.lactate,levels=design)
contrastsMatrix
```
According to the contrast matrix, the lactate and pregnant are differentially expressed overall (when the two groups show -1 and 1, this means they have different classifications based on the genes that identify them).

```{r VerifyDEStatistics}
# Step 3: Show statistics and estimated parameters for the two groups
fittedContrast <- contrasts.fit(fitted, contrastsMatrix) # Fit the contrast matrix based on the fitted voom transform (using linear model)
fittedContrast <- eBayes(fittedContrast) # Perform empirical Bayes on the variances & find t-values for each gene associated
dim(fittedContrast) # Verify dimension of the variances and means of each group (from the linear model above)

# Step 4: Use limma to generate a summary of the number of DE genes for the contrasted groups
fitSummary <- decideTests(fittedContrast)
summary(fitSummary)
```

```{r showDifferentialExpressionResults}
# To show the differentially expressed genes, create a graph from the decideTests to highlight the statistically significant genes
par(mfrow=c(1,2))
plotMD(fittedContrast,coef=1,status=fitSummary[,"B.PregVsLac"], values = c(-1, 1), hl.col=c("blue","red"))

# To further show the results, the volcano plot allows us to highlight the top genes from the contrastTest.
volcanoplot(fittedContrast,coef=1,highlight=50,names=fittedContrast$genes$SYMBOL, main="B.PregVsLac") # Show the top 50 statistically significant DE genes

```

## Gaussian Processes
Gaussian Processes are generic supervised learning methods designed to solve regression and probabilistic classification problems. They provide the advantages of the prediction interpolating the observations, the prediction being probabilistic meaning it can compute empirical confidence intervals and refit the prediction in some regions of interest, and that the kernels can be specified. Its disadvantages include the fact that they aren’t sparse and they lose efficiency in higher dimensional spaces. Consequently, when performing regression to find the best predictor or DE genes, Gaussian processes can be utilized to find the best function model. Taking a step further, Gaussian Process Regression is a nonparametric method that calculates the probability distribution of all admissible functions that fit the data. This will be used to calculate the posterior using the training data, and then copute the predictive posterior distribution on our points of interest.

### Example of 1-D Gaussian Process using a sin function
```{r Gaussian Process Testing Code}
library(GauPro)

#1-D, Not using kernels
n <- 12
x <- matrix(seq(0,1,length.out = n), ncol=1)
y <- sin(2*pi*x) + rnorm(n,0,1e-1)
gp <- GauPro::GauPro(X=x, Z=y)
curve(gp$pred(x));points(x,y)
curve(gp$pred(x)+2*gp$pred(x,T)$se,col=2,add=T);curve(gp$pred(x)-2*gp$pred(x,T)$se,col=2,add=T)

#Same as above, but with no noise
n <- 12
x <- matrix(seq(0,1,length.out = n), ncol=1)
y <- (2*x) %%1
gp <- GauPro::GauPro(X=x, Z=y)
curve(gp$pred(x));points(x,y)
curve(gp$pred(x)+2*gp$pred(x,T)$se,col=2,add=T);curve(gp$pred(x)-2*gp$pred(x,T)$se,col=2,add=T)
```

### Example of Kernel Gaussian Process using a sin function
```{r}
#Using Kernels
kern <- Matern52$new(0)
gpk <- GauPro_kernel_model$new(matrix(x, ncol=1), y, kernel=kern, parallel=FALSE)
if (requireNamespace("MASS", quietly = TRUE)) {
  plot(gpk)
}
```

## Using the above testing Gaussian Process Code we implement it in our own data.
```{r TrainGaussianProcesses}
library(pracma)
library(caTools)

# Reformat dglist to a suitable size
n <- 500
y <- dglist$counts[1:n,1]

sample <- sample.split(y, SplitRatio = 0.7) # Split using 70/30 ratio (backed up with research)

x_train <- matrix(seq(0,1,length.out = 350), ncol=1)
x_test <- matrix(seq(0,1,length.out = 150), ncol=1)
y_train <- subset(y, sample==TRUE)
y_test <- subset(y, sample==FALSE)

#Using Kernels
kern <- Matern52$new(0)
gpk <- GauPro_kernel_model$new(matrix(x_train, ncol=1), y_train, kernel=kern, parallel=FALSE)
if (requireNamespace("MASS", quietly = TRUE)) {
  plot(gpk)
}
```


## Predictions with GP
Utilizing Gaussian Processes as a linear regression, the final model can be utilized to predict the presence of differentially expressed genes using a testing RNA-sequence dataset. Moreover, the outcome of performing prediction with this model is a set of positive and negative outcomes for the analyzed dataset. These outcomes indicate whether the indicated gene is differentially expressed or not.


```{r predictions}
# Create a prediction curve for the test set using the model
curve(gpk$pred(x));points(x_test,y_test)

# Testing data here
#predicted <- predict(gpk, y_test)
#predicted.df <- data.frame(predicted)

```

```{r comparePredictions}
# To show that predictions vary each time with new testing and training sets, use a for loop to plot 5 different graphs
for (z in 1:5) {
  # Reformat dglist to a suitable size
  n <- 500
  y <- dglist$counts[1:n,1]

  sample <- sample.split(y, SplitRatio = 0.7) # Split using 70/30 ratio (backed up with research)

  x_train <- matrix(seq(0,1,length.out = 350), ncol=1)
  x_test <- matrix(seq(0,1,length.out = 150), ncol=1)
  y_train <- subset(y, sample==TRUE)
  y_test <- subset(y, sample==FALSE)

  #Using Kernels
  kern <- Matern52$new(0)
  gpk <- GauPro_kernel_model$new(matrix(x_train, ncol=1), y_train, kernel=kern, parallel=FALSE)

  # Create the prediction curve
  curve(gpk$pred(x));points(x_test,y_test)
}
```


## Covariance Function
Covariance models of RNA sequences are extremely sensitive and discriminative tool for searching for additional RNAs and RNA-related sequences in sequence databases. Generally, covariance functions measure how much two variables change together by using a kernel that describes the spatial or temporal covariance of the variable process. Models can be built automatically from the already existing sequence alignment in this case.
From the multiple models produced above, we can see that there is little variance between some of the graphs, but there is an occasional graph that will have a much different form than the others. This could be considered an outlier for the covariance function. We can take the parameters that were used in that outlier and add them to a list that will store all the parameters that will result in a poor estimate. From the graphs created it looks like the covariance function uses a Rational Quadratic Function.

## Addressing Gaussian Process Prior
Gaussian Process Prior is distribution on some unknown function in the context of regression. It is the assignment of a GP without exact knowledge of what the function is. After having observed some function values, the GP can be converted into a posterior over the functions.

## Posterior Predictions and Noise Reduction with Gaussian Processes
Noise is an addition to the functions to produce slightly different results that may result in the most accurate solution. It prompts change where a noise-free environment would settle. Below is our implementation of introducing noise into the Gaussian Process using the wvtool library.
```{r noise}
# Noise-free observations and predictions with noisy observations
library(wvtool)
# use gaussian process variable in noise.filter()
#noiseTest <- noise.filter(gp, n=15804, method="median") # Reduce noise?
#plot(myCPM[,1],countdata[,1],ylim=c(0,50),xlim=c(0,3))
```

## Optimization
Using the Berny Optimization Algorithm, the Gaussian process can be considerably enhanced. The steps of Berny's optimization algorithm are as follows.
- Any components of the gradient vector corresponding to frozen variables are set to zero or projected out, eliminating their direct contribution to the next optimization step.
- If a minimum is sought, perform a linear search between the latest point and the best previous point.
- If second derivatives are available at both points and a minimum is sought, a quintic polynomial fit is attempted first
  - If it does not have a minimum in the acceptable range or if second derivatives are not available, a constrained quartic fit is attempted.
  - If this fit fails or if the resulting step is unacceptable, a simple cubic is fit is done.
- Any quintic or quartic step is considered acceptable if the latest point is the best so far but if the newest point is not the best, the linear search must return a point in between the most recent and the best step to be acceptable.
- If all fits fail and the most recent step is the best so far, no linear step is taken.
- If all fits fail and the most recent step is not the best, the linear step is taken to the midpoint of the line connecting the most recent and the best previous points.
- If the latest point is the best so far or if a transition state is sought, a quadratic step is determined using the current second derivatives.
- If a linear search was done, the quadratic step is taken from the point extrapolated using the linear search and uses forces at that point estimated by interpolating between the forces at the two points used in the linear search.
- Any components of the step vector resulting from the quadratic step corresponding to frozen variables are set to zero or projected out.
- If the quadratic step exceeds the trust radius and a minimum is sought, the step is reduced in length to the trust radius by searching for a minimum of the quadratic function on the sphere having the trust radius.
- If a transition state is sought or if NRScale was requested, the quadratic step is simply scaled down to the trust radius.
- Finally, convergence is tested against criteria for the maximum force component, root-mean square force, maximum step component, and root-mean-square step.

## Conclusion
This project provided a strong challenge as the purpose was to develop a solution to a problem with little to no prior knowledge of the subject. Analyzing Gene Expression is something that is definitely outside the computer science peripheral, thus causing a lot of challenges in the completion of this project. A large portion of the project was dedicated to understanding Gene Expression and terminology associated with the idea, and the rest was dedicated to the application of determining whether the expression of a gene was affected by treatment. Below is our findings and our conclusion of the treatment.

The first steps we took in performing Gaussian Processes was to follow the data cleaning and refining from combine-australia.github.io (link down below). This allowed us to read from the source data provided and set up a list with the important information needed to preform analysis on. After performing quality control and data analysis on the dataset, we classified the RNA-sequences by counts per million. Normalizing the data, we were able to observe differential expressions between two classified groups using contrasts on a linear fit. Then, we attempted to perform a Gaussian process as a regression by splitting the data into training and testing sets. Using the training set, we performed Gaussian Processes using GauPro and made several predictions on the testing set (through multiple iterations and comparisons). Once we had our GauPro model, we were able to perform predictions using the testing set to create a best fit graph.




## References
https://combine-australia.github.io/RNAseq-R/06-rnaseq-day1.html
https://www.r-bloggers.com/2012/04/gaussian-process-regression-with-r/
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4827276/
https://cran.r-project.org/web/packages/GauPro/vignettes/GauPro.html
https://www.rdocumentation.org/packages/kernlab/versions/0.9-29/topics/kernelMatrix
https://www.rdocumentation.org/packages/wvtool/versions/1.0/topics/noise.filter
https://www.geeksforgeeks.org/covariance-and-correlation-in-r-programming/
https://www.yourgenome.org/facts/what-is-gene-expression
https://www.scribbr.com/methodology/control-group/
https://scikit-learn.org/stable/modules/gaussian_process.html
https://www.ncbi.nlm.nih.gov/labs/pmc/articles/PMC308124/pdf/nar00035-0157.pdf
http://krasserm.github.io/2018/03/19/gaussian-processes/
https://gaussian.com/opt/
https://towardsdatascience.com/quick-start-to-gaussian-process-regression-36d838810319