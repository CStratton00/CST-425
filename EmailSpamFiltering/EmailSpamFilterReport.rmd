---
title: "Email Spam Filtering"
output: html_notebook
---

## Step 1: Data Setup and Exploration

### Setup Knitr
```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

### Get the appropriate libraries
```{r libraries}
library(tidyverse)
library(e1071)
library(mice)
library(Amelia)
library(scales)

wd <- getwd()
wd
```



### Load the Data
```{r loadData}
# Get Data from ClassExamples Directory
spam <- read_csv(file='EmailSpamFiltering/completeSpamAssassin.csv')
head(spam)
```

# Explore the model by getting a glimpse of the data.
```{r exploreModel}
glimpse(spam)
```

## Step 2: Preparing training and testing sets
```{r model}
# Set a seed to randomize model generation
set.seed(1234)

# Create a sample of the data
sample_set <- sample(1:dim(spam)[1], dim(spam)[1]*0.80)

# Split training and testing set using 80:20 split
spam_train <- spam[sample_set,]
spam_test <- spam[-sample_set,]
```

## Step 3: Build the Bayesian Model (Naive)
```{r buildModel}
# Build the naive model based on training set
spam_mod <- naiveBayes(Label ~ ., data = spam_train, laplace = 1)

```


## Step 4: Improve the Bayesian Model
```{r improveModel}
#-----------------------------------------------------------------------------------------------
#Get rid of missing values

#Naive Bayes is handy due to laplace smoothing which can allow

#spam.df <- data.frame(spam)
glimpse(spam)

spam[spam == "empty"] <- NA
sum(is.na(spam))
spam.removedNA<- na.omit(spam)


glimpse(spam.removedNA)


#-----------------------------------------------------------------------------------------------
#Make all words lowercase to prevent multiple matching

# The idea behind making all of the text lowercase would be to eliminate cases where words that are the same but have different capitalization are considered different. Example being (free and FREE). This would be beneficial if in the context of the word they mean the same, but in this case, a sign of a spam email would be words in all caps, meaning that it is important to keep the text as is to increase the accuracy of the model.

# Lowercase the model
#spam$Body <- tolower(spam$Body)
#spam$Body <- toupper(spam$Body)
#-----------------------------------------------------------------------------------------------

##Changing Testing and Training set ratios

# Create a sample of the data
sample_set <- sample(1:dim(spam)[1], dim(spam)[1]*0.75)

# Split training and testing set using 75:25 split
spam_train <- spam[sample_set,]
spam_test <- spam[-sample_set,]

#-----------------------------------------------------------------------------------------------


```


## Step 5: Interpret the Model Output
```{r interpretModel}
# TK
```


## Step 6: Estimate Errors
```{r errorEstimation}

```


## Step 7: Make predictions using the test set
```{r predict}
spam_pred <- predict(spam_mod, newdata = spam_test, type = "raw")
head(spam_pred_raw)
spam_pred <- predict(spam_mod, newdata = spam_test, type = "class")
head(spam_pred_class)
```

## Step 8: Model Verification
```{r modelVerification}
# Get Data from ClassExamples Directory
spam_test2 <- read_csv(file='EmailSpamFiltering/lingSpam.csv')
head(spam_test2)
glimpse(spam_test2)

spam_pred2 <- predict(spam_mod, newdata = spam_test2, type = "class")
head(spam_pred2)
```

```{r seeResults}
# Print Confusion Matrix
spam_pred_table2 <- table(spam_test2$Label, spam_pred2)
spam_pred_table2

# Accuracy
sum(diag(spam_pred_table2)) / nrow(spam_test2)
```

## Step 9: Final Spam Identification Results

### Create confusion matrix of our results
```{r confusion}
# Print Confusion Matrix
spam_pred_table <- table(spam_test$Label, spam_pred)
spam_pred_table

# Accuracy
sum(diag(spam_pred_table)) / nrow(spam_test)
```


## References
https://www.kaggle.com/nitishabharathi/email-spam-dataset