#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
data[2,]
#IQR(data[2,],na.rm=TRUE)
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
data[:2,]
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
data[2][2]
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
data[,"Open"]
#IQR(data[2,],na.rm=TRUE)
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
IQR(data[,"Open])
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
IQR(data[,"Open"])
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
plot(data)
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
plot(data[,"Open","High"])
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
plot(data["Open","High"])
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
x <- data[,"Open"]
y <- data[,"High"]
plot(x,y)
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
trend.line(openx,highy,type="linear", plot = TRUE)
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
lines(predict(lm(data~openx)),col='highy')
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
lines(predict(lm(highy~openx)),col='green')
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
abline(lm(highy~openx))
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
abline(lm(highy~openx))
#likelihood <- function(p){
#dbinom(openx,263,p)
#}
#likelihood(openx)
hist(openx, prob = TRUE, ylim = c(0,max(fun))),
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
abline(lm(highy~openx))
#likelihood <- function(p){
#dbinom(openx,263,p)
#}
#likelihood(openx)
hist(openx, prob = TRUE, ylim = c(0,max(fun)),
main = "Histogram with density curve")
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
abline(lm(highy~openx))
#likelihood <- function(p){
#dbinom(openx,263,p)
#}
#likelihood(openx)
x2 <- seq(min(openx),max(openx), length = 40)
fun <- dnorm(x2, mean = mean(openx), sd = sd(openx))
hist(openx, prob = TRUE),
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
abline(lm(highy~openx))
#likelihood <- function(p){
#dbinom(openx,263,p)
#}
#likelihood(openx)
x2 <- seq(min(openx),max(openx), length = 40)
fun <- dnorm(x2, mean = mean(openx), sd = sd(openx))
hist(openx, prob = TRUE)
main = "Histogram with density curve")
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
abline(lm(highy~openx))
#likelihood <- function(p){
#dbinom(openx,263,p)
#}
#likelihood(openx)
x2 <- seq(min(openx),max(openx), length = 40)
fun <- dnorm(x2, mean = mean(openx), sd = sd(openx))
hist(openx, prob = TRUE,
main = "Histogram with density curve")
lines(density(x), col=4, lwd = 2)
#Once I have moved my working directory to the location of my desired .csv file, I can store the name of the file in a variable. In this instance I store it in "file".
file <- 'S&P500.csv'
#I use the built in R function read.csv() to read my .csv file and store it into a variable.
data <- read.csv(file)
#This will directly print out my .csv file as it is stored in excel.
data
#Running the summary function will preform analytical functions like min, 1st/3rd Quartile, Median, Mean, and max.
summary(data)
#data[,"Open"]
#Prints out IQR for Open, High, Low, and Closing Values for the S&P500 stock.
IQR(data[,"Open"])
IQR(data[,"High"])
IQR(data[,"Low"])
IQR(data[,"Close"])
openx <- data[,"Open"]
highy <- data[,"High"]
plot(openx,highy)
abline(lm(highy~openx))
x2 <- seq(min(openx),max(openx), length = 40)
fun <- dnorm(x2, mean = mean(openx), sd = sd(openx))
hist(openx, prob = TRUE,
main = "Histogram with density curve")
lines(density(openx), col=4, lwd = 2)
getwd()
knitr::opts_chunk$set(echo = TRUE)
#Loading required packages
install.packages('tidyverse')
library(tidyverse)
install.packages('ggplot2')
library(ggplot2)
install.packages('caret')
library(caret)
install.packages('caretEnsemble')
library(caretEnsemble)
install.packages('psych')
library(psych)
install.packages('Amelia')
library(Amelia)
install.packages('mice')
library(mice)
install.packages('GGally')
install.packages("ggplot2")
library(GGally)
install.packages('rpart')
library(rpart)
install.packages('randomForest')
install.packages("rpart")
library(randomForest)
install.packages("Rtools")
knitr::opts_chunk$set(echo = TRUE)
#Loading required packages
install.packages('tidyverse')
library(tidyverse)
install.packages('ggplot2')
library(ggplot2)
install.packages('caret')
library(caret)
install.packages('caretEnsemble')
library(caretEnsemble)
install.packages('psych')
library(psych)
install.packages('Amelia')
library(Amelia)
install.packages('mice')
library(mice)
install.packages('GGally')
library(GGally)
install.packages('rpart')
library(rpart)
install.packages('randomForest')
library(randomForest)
install.packages("rpart")
write('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', file = "~/.Renviron", append = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(e1071)
library(mice)
library(Amelia)
library(scales)
library(ggplot2)
install.packages("dplyr")
# Get Data from ClassExamples Directory
spam <- read_csv(file='EmailSpamFiltering/completeSpamAssassin.csv')
setwd("C:/GCU Academics/Junior Year/Second Semester/CST-425/CLC Shared GitHub Repository/Cloned Repository/EmailSpamFiltering")
# Get Data from ClassExamples Directory
spam <- read_csv(file='completeSpamAssassin.csv')
setwd("C:/GCU Academics/Junior Year/Second Semester/CST-425/CLC Shared GitHub Repository/Cloned Repository/EmailSpamFiltering")
# Get Data from ClassExamples Directory
spam <- read_csv(file='completeSpamAssassin.csv')
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(e1071)
library(mice)
library(Amelia)
library(scales)
library(ggplot2)
# Get Data from ClassExamples Directory
spam <- read_csv(file='completeSpamAssassin.csv')
# Get Data from ClassExamples Directory
spam <- read_csv(file='C:/GCU Academics/Junior Year/Second Semester/CST-425/CLC Shared GitHub Repository/Cloned Repository/EmailSpamFiltering/completeSpamAssassin.csv')
head(spam,1)
glimpse(spam)
#------------------------------------Get rid of missing values---------------------------------------------------------
glimpse(spam)
#Change all "empty" spam emails to NA
spam[spam == "empty"] <- NA
#Count the amount of emails that have NA
sum(is.na(spam))
#Remove all email cases with NA in them
spam.removedNA <- na.omit(spam)
glimpse(spam.removedNA)
#-----------------------Lowercase/Upercase (Theoretical Implementation)-----------------------------------------
#Make all words lowercase to prevent multiple matching
# Lowercase the model
#spam$Body <- tolower(spam$Body)
#spam$Body <- toupper(spam$Body)
#-----------------Changing Testing and Training Set Ratios (Theoretical Implementation)---------------------------
# Create a sample of the data
#set.seed(1234)
#sample_set <- sample(1:dim(spam.removedNA)[1], dim(spam.removedNA)[1]*0.75)
#Split training and testing set using 75:25 split
#spam_train <- spam[sample_set,]
#spam_test <- spam[-sample_set,]
# Set a seed to randomize model generation
set.seed(1234)
# Create a sample of the data
sample_set <- sample(1:dim(spam.removedNA)[1], dim(spam.removedNA)[1]*0.80)
# Split training and testing set using 80:20 split
spam_train <- spam.removedNA[sample_set,]
spam_test <- spam.removedNA[-sample_set,]
# Build the naive model based on training set
spam_mod <- naiveBayes(Label ~ ., data = spam_train, laplace = 1)
spam_pred_raw <- predict(spam_mod, newdata = spam_test, type = "raw")
head(spam_pred_raw)
spam_pred_class <- predict(spam_mod, newdata = spam_test, type = "class")
head(spam_pred_class)
# accuracy <- weighted.mean(0:spam_pred_raw,1:spam_pred_raw)
# spam_error_rate <- 1-accuracy
# Print Confusion Matrix
spam_pred_table <- table(spam_test$Label, spam_pred_class)
spam_pred_table
# State the model accuracy
sum(diag(spam_pred_table)) / nrow(spam_test)
# Ensure the seed is set to 1234
set.seed(1234)
# Get Data from ClassExamples Directory
spam_test2 <- read_csv(file='EmailSpamFiltering/lingSpam.csv')
# Ensure the seed is set to 1234
set.seed(1234)
# Get Data from ClassExamples Directory
spam_test2 <- read_csv(file='C:/GCU Academics/Junior Year/Second Semester/CST-425/CLC Shared GitHub Repository/Cloned Repository/EmailSpamFiltering/lingSpam.csv')
head(spam_test2)
glimpse(spam_test2)
# Make a prediction for the lingSpam dataset
spam_pred2 <- predict(spam_mod, newdata = spam_test2, type = "class")
head(spam_pred2)
# Print Confusion Matrix
spam_pred_table2 <- table(spam_test2$Label, spam_pred2)
spam_pred_table2
# State the prediction accuracy
sum(diag(spam_pred_table2)) / nrow(spam_test2)
# Build the naive model based on training set
spam_mod <- naiveBayes(Label ~ ., data = spam_train, laplace = 1)
head(spam_mod,1)
# Build the naive model based on training set
spam_mod <- naiveBayes(Label ~ ., data = spam_train, laplace = 1)
#Returns the Naive Bayes calculations on each
head(spam_mod,2)
View(spam_mod)
# Build the naive model based on training set
spam_mod <- naiveBayes(Label ~ ., data = spam_train, laplace = 1)
#Returns the Naive Bayes calculations on each
head(spam_mod,1)
# Print Confusion Matrix
spam_pred_table2 <- table(spam_test2$Label, spam_pred2)
spam_pred_table2
# State the prediction accuracy
sum(diag(spam_pred_table2)) / nrow(spam_test2)
# Print Confusion Matrix
spam_pred_table <- table(spam_test$Label, spam_pred_class)
spam_pred_table
# State the model accuracy
sum(diag(spam_pred_table)) / nrow(spam_test)
