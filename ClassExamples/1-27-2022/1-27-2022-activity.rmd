---
title: "R Notebook"
output: html_notebook
---
# Objective: Examine the records of existing patients and use that information
# to predict whether a particular patient is likely to suffer from heart disease or not.

# Install the packages needed for this code file
# install.packages("e1071")
```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


```{r libraries}
library(tidyverse)
library(e1071)
library(mice)
library(Amelia)
library(scales)
```

#----------------------------------------------------------------
#' #1. Load the Data
#----------------------------------------------------------------

# Load the data and use the `col_types` argument to specify type of
# all columns('n' stands for numerical and 'f' stands for factor).
```{r loadData}
# Get Data from ClassExamples Directory
heart <- read_csv(file='C:/GCU Academics/Junior Year/Second Semester/CST-425/CLC Shared GitHub Repository/Cloned Repository/ClassExamples/1-27-2022/heart.csv', col_types = "nffnnffnfnfnff")
# heartDF <- ldply(heart, read_csv, col_names = TRUE, )
```


# Get a glimpse of the data.
```{r glimpse}
glimpse(heart)
```


#----------------------------------------------------------------
#' #2. Explore and Prepare the Data
#----------------------------------------------------------------
# Show a set of descriptive statistics for every variable in the data.

```{r explore}
```

Note that there are some missing values in the dataset. Also, some of the numeric features have a wider range of values than others.

How do you handle these missing values?
Response: Naive Bayes model works well with missing values. It can predict a model even with missing data

Do you have to normalize data to overcome the wide range in values?
Response: No, you do not have to normalize the data to overcome the wide range in values in the dataset.

Do a little research about how is naÃ¯ve Bayes affected by these issues.

# Using the sample() function, let's create our training and test datasets with a 75% to 25% split.
# The set.seed() function ensures to get the same result every time we run a random sampling process.


# Check the proportions for the class between all 3 sets.


#----------------------------------------------------------------
#' #3. Build the Model
#----------------------------------------------------------------


# Train a new model using the naiveBayes() function.
```{r model}
# Set a seed to randomize model generation
set.seed(1234)

# Create a sample of the data
sample_set <- sample(c(1:dim(heart)[1]), dim(heart)[1]*0.75)

# Split training and testing set using 75:25 split
heart_train <- heart[sample_set,]
heart_test <- heart[-sample_set,]

# Build the naive model based on training set
heart_mod <- naiveBayes(heartDisease ~ ., data = heart_train, laplace = 1)
heart_mod
```

#----------------------------------------------------------------
#' #4. Evaluate the Model's Performance
#----------------------------------------------------------------
# Use the model to predict the class of the test instances.
```{r predict}
heart_pred <- predict(heart_mod, newdata = heart_test, type = "raw")
heart_pred
heart_pred <- predict(heart_mod, newdata = heart_test, type = "class")
heart_pred
```

# Create confusion matrix of our results.
```{r confusion}
# Print Confusion Matrix
heart_pred_table <- table(heart_test$heartDisease, heart_pred)
heart_pred_table

# Accuracy
sum(diag(heart_pred_table)) / nrow(heart_test)
```

# What is the accuracy of our prediction?
The accuracy of our model is 80.4% with a seed of 1234


The results show that the predictive accuracy of our model is ....
The range of accuracy from our model with a 75/25 ratio from varying seeds is from 75%-85% accurate.

Is this good?
This percentage of accuracy is very good for Naive Bayes due to it being quick in nature and having 6% missing data entries.

How important is prediction accuracy?
Prediction accuracy is important because the results from the prediction accuracy will give the result on how well our
data set will be able to predict a set of events. Having a very high percentage will mean we have a very good model.

Peek at near future concepts: resampling and k-fold cross-validation
Did in class ^^
#----------------------------------------------------------------
#' #5. Interpret the results
#----------------------------------------------------------------
Based on age,sex,painType,restingBP,cholesterol,highBloodSugar,restingECG,restingHR,exerciseAngina,STdepression,STslope,coloredVessels and defectType, we can predict if a patient has heart disease with an accuracy of 80.4%.
